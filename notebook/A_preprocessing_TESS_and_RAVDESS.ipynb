{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../pyfiles/\")\n",
    "from util import play_audio, silence_removal, min_max\n",
    "from get_mel_spectrogram import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "---\n",
    "In this notebook, I'm going to explain the detail of the datasets I'll use: [RAVDESS](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio) and [TESS](https://www.kaggle.com/ejlok1/toronto-emotional-speech-set-tess). Additionally, some preprocessing techniques are employed in this notebook for training, such as silent removal and mel-spectrogram conversion. At first, I'm going to introduce the basic information of the datasets.\n",
    "\n",
    "---\n",
    "I won't explain some features which are not related to my usage.\n",
    "\n",
    "### Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)\n",
    "This dataset includes speech and song audio whose sampling rate is 48kHz and audio depth is 16bit.\n",
    "2 statements are spoken by 24 actors(12 female and 12 male) in 8 emotions such as \"neutral\", \"happy\", and so on.\n",
    "Please visit [this link](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio) to download or you can download quickly by referring `A-download_Download_TESS_RAVDESS.ipynb`.\n",
    "\n",
    "### Toronto emotional speech set (TESS)\n",
    "This is also an audio dataset labeled with 7 emotions such as \"fear\", \"disgust\" and so on.\n",
    "The sampling rate is 24414Hz.\n",
    "The sentence is spoken by 2 female speakers and every audio is prefaced with \"Say the word\" followed by a certain word. Please visit [this link](https://www.kaggle.com/ejlok1/toronto-emotional-speech-set-tess) to download or, of course, you can download quickly by referring `A-download_Download_TESS_RAVDESS.ipynb`.\n",
    "\n",
    "---\n",
    "Since they have different sampling rates, it's downsampled to 22050Hz and its silent section is removed.\n",
    "As the data length is different from each other, it's adjusted by random-zero-padding or random-cropping.\n",
    "In addition, the audio labeled with \"calm\" is integrated into the label \"neutral\" due to the similarity.\n",
    "Eventually, the dataset is utilized in the following condition.\n",
    "- sampling rate: 22050 Hz\n",
    "- no silent section\n",
    "- emotions: \"neutral\", \"happy\", \"sad\", \"angry\"\n",
    "- audio depth: 16 bit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "---\n",
    "the original directory structure is not intuitive and it's difficult to understand at a glance. I've organized a new 'directory' named 'audio_files' to store all data in a methodical order. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "ravdess_speech_dir = \"./../../../dataset/RAVDESS/speech/\"\n",
    "ravdess_song_dir = \"./../../../dataset/RAVDESS/song/\"\n",
    "# --------------------------------- #\n",
    "\n",
    "os.makedirs(ravdess_song_dir+\"Actor_18\", exist_ok=True)\n",
    "actor_speech_dir = glob.glob(ravdess_speech_dir + \"Actor*/\")\n",
    "actor_speech_dir.sort()\n",
    "actor_song_dir = glob.glob(ravdess_song_dir + \"Actor*/\")\n",
    "actor_song_dir.sort()\n",
    "\n",
    "r_actor_ids = np.array([str(i) for i in range(1, 25)])\n",
    "r_emotions = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprised\"]\n",
    "r_statements = [\"kids\", \"dogs\"]\n",
    "r_types = [\"normal_intensity_1\", \"normal_intensity_2\", \"strong_intensity_1\", \"strong_intensity_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = {}\n",
    "audio_files[\"ravdess\"] = {}\n",
    "for record_type in [\"speech\", \"song\"]:\n",
    "    audio_files[\"ravdess\"][record_type] = {}\n",
    "    for i in range(len(r_actor_ids)):\n",
    "        audio_files[\"ravdess\"][record_type][r_actor_ids[i]] = {} \n",
    "        files = glob.glob(actor_speech_dir[i] + \"*.wav\")\n",
    "        for j in range(len(r_emotions)):\n",
    "            audio_files[\"ravdess\"][record_type][r_actor_ids[i]][r_emotions[j]] = {}\n",
    "            for k in range(len(r_statements)):\n",
    "                audio_files[\"ravdess\"][record_type][r_actor_ids[i]][r_emotions[j]][r_statements[k]] = []\n",
    "                for path in files:\n",
    "                    basename = os.path.basename(path).split(\".\")[0]\n",
    "                    if int(basename[6:8])==j+1:\n",
    "                        if int(basename[12:14])==k+1:\n",
    "                            audio_files[\"ravdess\"][record_type][r_actor_ids[i]][r_emotions[j]][r_statements[k]].append(path)\n",
    "                    audio_files[\"ravdess\"][record_type][r_actor_ids[i]][r_emotions[j]][r_statements[k]].sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Make some directories in a selected directory.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "ravdess_save_dir = \"./../../../dataset/RAVDESS/preprocessed/\"\n",
    "# --------------------------------- #\n",
    "\n",
    "os.makedirs(ravdess_save_dir, exist_ok=True)\n",
    "for data_type in [\"audio\", \"feature\"]:\n",
    "    for tp in [\"speech\", \"song\"]:\n",
    "        for actor in r_actor_ids:\n",
    "            dir_actor = ravdess_save_dir + f\"{data_type}/{tp}/{actor}\"\n",
    "            os.makedirs(dir_actor, exist_ok=True)\n",
    "            for emotion in r_emotions:\n",
    "                dir_path = ravdess_save_dir + f\"{data_type}/{tp}/{actor}/{emotion}\"\n",
    "                os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "tess_speech_dir = \"./../../../dataset/TESS/\"\n",
    "# --------------------------------- #\n",
    "\n",
    "dir_list = glob.glob(tess_speech_dir + \"*F*/\")\n",
    "dir_list.sort()\n",
    "\n",
    "t_actor_ids = [\"OAF\", \"YAF\"]\n",
    "t_emotions = [\"neutral\", \"happy\", \"sad\", \"angry\", \"fear\", \"disgust\", \"surprised\"]\n",
    "t_emotions_ = [\"neutral\", \"happy\", \"sad\", \"angry\", \"fear\", \"disgust\", \"ps\"]\n",
    "commands = []\n",
    "for path in glob.glob(dir_list[4]+\"*wav\"):\n",
    "    basename = os.path.basename(path)\n",
    "    commands.append(basename.split(\"_\")[1])\n",
    "commands.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files[\"tess\"] = {}\n",
    "for actor in t_actor_ids:\n",
    "    audio_files[\"tess\"][actor] = {} \n",
    "    for i in range(len(t_emotions)):\n",
    "        emotion = t_emotions[i]\n",
    "        audio_files[\"tess\"][actor][emotion] = {}\n",
    "#         print(actor, emotion)\n",
    "        for dir in dir_list:\n",
    "            files = glob.glob(dir + f\"{actor}*{t_emotions_[i]}*.wav\")\n",
    "#             print(actor, emotions_[i])\n",
    "#             print(dir)\n",
    "            if bool(len(files)):\n",
    "                files.sort()\n",
    "                for j in range(len(commands)):\n",
    "                    command = commands[j]\n",
    "                    try:\n",
    "                        audio_files[\"tess\"][actor][emotion][command] = files[j]\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Make some directories in a selected directory.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "tess_save_dir = \"./../../../dataset/TESS/preprocessed/\"\n",
    "# --------------------------------- #\n",
    "\n",
    "os.makedirs(tess_save_dir, exist_ok=True)\n",
    "\n",
    "for data_type in [\"audio\", \"feature\"]:\n",
    "    for actor in t_actor_ids:\n",
    "        dir_actor = tess_save_dir + f\"{data_type}/{actor}\"\n",
    "        os.makedirs(dir_actor, exist_ok=True)\n",
    "        for emotion in t_emotions:\n",
    "            dir_path = tess_save_dir + f\"{data_type}/{actor}/{emotion}\"\n",
    "            os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others\n",
    "---\n",
    "Some audio files have enough length for mel-spectrogram computation and some don't. Therefore, I need to compensate them, and it's done by a function transform defined below. And 'args' indicates the parameters for mel-spectrogram computation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(array, target=2**15):\n",
    "    ndim = array.ndim\n",
    "    if ndim==1:\n",
    "        array = np.reshape(array, (array.shape[0], 1))\n",
    "    length = array.shape[0]\n",
    "    zeros = np.zeros((target-length, 1))\n",
    "    start = int((target-length)/2)\n",
    "    new_array = np.concatenate([zeros[:start,:], min_max(array, mean0=True), zeros[start:,:]])\n",
    "    if ndim==1:\n",
    "        new_array = np.reshape(new_array, (new_array.shape[0],))\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"max_wav_value\"] = 2**15\n",
    "args[\"filter_length\"] = 1024\n",
    "args[\"hop_length\"] = 256\n",
    "args[\"win_length\"] = 1024\n",
    "args[\"n_mel_channels\"] = 80\n",
    "args[\"sampling_rate\"] = 22050\n",
    "args[\"mel_fmin\"] = 0\n",
    "args[\"mel_fmax\"] = 8000\n",
    "timesize = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "save = False # save or not\n",
    "# --------------------------------- #\n",
    "\n",
    "for actor in r_actor_ids:\n",
    "    print(actor)\n",
    "    for emotion in r_emotions:\n",
    "        for statement in r_statements:\n",
    "            for tp in [\"speech\", \"song\"]:\n",
    "                path_list = audio_files[\"ravdess\"][tp][actor][emotion][statement]\n",
    "                for i in range(len(path_list)):\n",
    "                    path = path_list[i]\n",
    "                    x, fs = librosa.load(path, args[\"sampling_rate\"])\n",
    "                    x = silence_removal(x)\n",
    "                    if len(x) > 3*fs:\n",
    "                        mel = audio2mel(None, args, x, fs)\n",
    "                    else:\n",
    "                        x = transform(x, 3 * fs)\n",
    "                        mel = audio2mel(None, args, x, fs)\n",
    "                    \n",
    "                    audio_path = ravdess_save_dir + f\"audio/{tp}/{actor}/{emotion}/speech_{actor}_{emotion}_{statement}_{r_types[i]}.wav\"\n",
    "                    feature_path = ravdess_save_dir + f\"feature/{tp}/{actor}/{emotion}/speech_{actor}_{emotion}_{statement}_{r_types[i]}.pkl\"\n",
    "                    if save:\n",
    "                        sf.write(audio_path, x, fs, subtype='PCM_24')\n",
    "                        with open(feature_path, mode='wb') as f:\n",
    "                            pickle.dump(mel, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "save = False\n",
    "# --------------------------------- #\n",
    "\n",
    "for actor in t_actor_ids:\n",
    "    print(actor)\n",
    "    for emotion in t_emotions:\n",
    "        print(\"   \", emotion)\n",
    "        for command in commands:\n",
    "            path = audio_files[\"tess\"][actor][emotion][command]\n",
    "            x, fs = librosa.load(path, args[\"sampling_rate\"])\n",
    "            x = silence_removal(x)\n",
    "            if len(x) > 3*fs:\n",
    "                mel = audio2mel(None, args, x, fs)\n",
    "            else:\n",
    "                x = transform(x, 3 * fs)\n",
    "                mel = audio2mel(None, args, x, fs)\n",
    "\n",
    "            audio_path = tess_save_dir + f\"audio/{actor}/{emotion}/{actor}_{emotion}_{command}.wav\"\n",
    "            feature_path = tess_save_dir + f\"feature/{actor}/{emotion}/{actor}_{emotion}_{command}.pkl\"\n",
    "            \n",
    "            if save:\n",
    "                sf.write(audio_path, x, fs, subtype='PCM_24')\n",
    "                with open(feature_path, mode='wb') as f:\n",
    "                    pickle.dump(mel, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
